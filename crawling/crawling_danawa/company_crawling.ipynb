{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup   \n",
    "import time\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making date and company list\n",
    "def making_list():\n",
    "    now = datetime.now()\n",
    "    previous_month = now - relativedelta(months=1)\n",
    "    last_6_months = []\n",
    "    for i in range(6):\n",
    "        month_date = previous_month - relativedelta(months=i)\n",
    "        last_6_months.append(month_date.strftime('%Y-%m'))\n",
    "    last_6_months.reverse()\n",
    "    return last_6_months\n",
    "\n",
    "# making company_df with crawling\n",
    "def make_company_df(driver):\n",
    "    url = \"https://auto.danawa.com/auto/?Work=record&Tab=Grand&Month=2024-06-00\"\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    tbody_tag = soup.select_one(\"#autodanawa_gridC > div.gridMain > article > main > div:nth-child(1) > table > tbody \")\n",
    "    \n",
    "    for i in range(1, len(tbody_tag.find_all('tr')) + 1): \n",
    "        brand_id_tag = soup.select_one(f\"#autodanawa_gridC > div.gridMain > article > main > div:nth-child(1) > table > tbody > tr:nth-child({i}) > td.title > a\")\n",
    "        brand_id = urlparse(brand_id_tag['href']).query.split('Brand=')[1].split('&')[0]\n",
    "\n",
    "        brand_img = soup.select_one(f\"#autodanawa_gridC > div.gridMain > article > main > div:nth-of-type(1) > table > tbody > tr:nth-of-type({i}) > td.title > a > img\").get('src')\n",
    "        \n",
    "        brand_name = soup.select_one(f'#autodanawa_gridC > div.gridMain > article > main > div:nth-child(1) > table > tbody > tr:nth-child({i}) > td.title > a').get_text(strip=True)\n",
    "\n",
    "        company.append([int(brand_id), brand_img, brand_name])\n",
    "\n",
    "    company_df = pd.DataFrame(company, columns=['company_id', 'company_logo', 'company_name'])\n",
    "    \n",
    "    return company_df\n",
    "\n",
    "# making company_vehicle_df with crawling\n",
    "def make_company_vehicle_df(driver):\n",
    "    for date in making_list():\n",
    "        url = f\"https://auto.danawa.com/auto/?Work=record&Tab=Grand&Month={date}\" + \"-00\"\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        tbody_tag = soup.select_one(\"#autodanawa_gridC > div.gridMain > article > main > div:nth-child(1) > table > tbody\")\n",
    "        \n",
    "        for i in range(1, len(tbody_tag.find_all('tr'))+1):\n",
    "            brand_id_tag = soup.select_one(f\"#autodanawa_gridC > div.gridMain > article > main > div:nth-child(1) > table > tbody > tr:nth-child({i}) > td.title > a\")\n",
    "            brand_id = urlparse(brand_id_tag['href']).query.split('Brand=')[1].split('&')[0]\n",
    "\n",
    "            brand_volume = soup.select_one(f\"#autodanawa_gridC > div.gridMain > article > main > div:nth-child(1) > table > tbody > tr:nth-child({i}) > td.num\").get_text()\n",
    "            brand_volume = brand_volume.rstrip('그래프로 보기')\n",
    "\n",
    "            brand_share = soup.select_one(f\"#autodanawa_gridC > div.gridMain > article > main > div:nth-child(1) > table > tbody > tr:nth-child({i}) > td.rate.right\").get_text()\n",
    "\n",
    "            td_element = soup.select_one(f\"#autodanawa_gridC > div.gridMain > article > main > div:nth-child(1) > table > tbody > tr:nth-child({i}) > td:nth-child(6)\")\n",
    "\n",
    "            brand_mom = td_element.contents[0].strip()\n",
    "            \n",
    "            brand_mos = soup.select_one(f\"#autodanawa_gridC > div.gridMain > article > main > div:nth-child(1) > table > tbody > tr:nth-child({i}) > td:nth-child(6) > span\").get_text()\n",
    "\n",
    "            company_vehicle.append([date, int(brand_id), int(brand_volume.replace(',','')), float(brand_share.replace('%','')), int(brand_mom.replace(',','')), brand_mos])\n",
    "\n",
    "    company_vehicle_df = pd.DataFrame(company_vehicle, columns=['company_date', 'company_id', 'sales_volume', 'company_share' ,'company_month_over_month', 'company_salse_by_month'])\n",
    "\n",
    "    return company_vehicle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list\n",
    "company = []\n",
    "company_vehicle = []\n",
    "\n",
    "# define driver & making dataframe\n",
    "driver = webdriver.Chrome()\n",
    "company_df = make_company_df(driver)\n",
    "driver.quit() \n",
    "\n",
    "# define driver & making dataframe\n",
    "driver = webdriver.Chrome()\n",
    "company_vehicle_df = make_company_vehicle_df(driver)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPEND MYSQL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making connection and insert data\n",
    "con = pymysql.connect (\n",
    "    host = 'localhost',\n",
    "    user = 'root',\n",
    "    password= 'root1234',\n",
    "    database= 'vehicle',\n",
    "    charset='utf8'\n",
    ")\n",
    "\n",
    "DATABASE_URI = 'mysql+pymysql://root:root1234@localhost:3306/vehicle'\n",
    "\n",
    "engine = create_engine(DATABASE_URI)\n",
    "\n",
    "company_df.to_sql('company', con=engine, if_exists='append', index=False)\n",
    "company_vehicle_df.to_sql('company_vehicle', con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
