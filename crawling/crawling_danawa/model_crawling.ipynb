{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup   \n",
    "import time\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making model_df row by row\n",
    "def make_model_df(soup):\n",
    "    model = []\n",
    "\n",
    "    default_img_url = 'https://autoimg.danawa.com/html/images/blank/model_200_100.png'\n",
    "    \n",
    "    all_rows = soup.select('#autodanawa_gridC > div.gridMain > article > main > div > table.recordTable.model > tbody > tr') \n",
    "    rows = [row for row in all_rows if not row.get('class')]\n",
    "    \n",
    "    for row in rows:\n",
    "        \n",
    "        model_id_tag = row.select_one('td.title > a')\n",
    "        model_id = urlparse(model_id_tag['href']).query.split('Model=')[1].split('&')[0]\n",
    "        \n",
    "        img_src =  row.select_one('td.title > a > img').get('src')\n",
    "        if not img_src.startswith('https://'):\n",
    "            img_src = default_img_url\n",
    "        \n",
    "        name = row.select_one('td.title > a').get_text(strip=True)\n",
    "        search = f'https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&ssc=tab.nx.all&query={name}'\n",
    "        \n",
    "        model.append([int(model_id), img_src, name, search])\n",
    "\n",
    "    model_df = pd.DataFrame(model, columns=['model_id', 'model_img', 'model_name', 'model_search_link'])\n",
    "\n",
    "    return model_df\n",
    "\n",
    "# making model_vehicle_df row by row\n",
    "def make_model_vehicle_df(company, month, soup):\n",
    "    model_vehicle = []\n",
    "\n",
    "    all_rows = soup.select('#autodanawa_gridC > div.gridMain > article > main > div > table.recordTable.model > tbody > tr')\n",
    "    rows = [row for row in all_rows if not row.get('class')]\n",
    "\n",
    "    for row in rows:\n",
    "        \n",
    "        model_id_tag = row.select_one('td.title > a')\n",
    "        if model_id_tag:\n",
    "            model_id = urlparse(model_id_tag['href']).query.split('Model=')[1].split('&')[0]\n",
    "\n",
    "        volum = row.select_one('td.num').get_text(strip=True).rstrip('그래프로 보기')\n",
    "\n",
    "        share = row.select_one('td.rate.right').get_text(strip=True)\n",
    "\n",
    "        mom = row.select_one('td:nth-child(7)').contents[0].strip()\n",
    "\n",
    "        mos = row.select_one('td:nth-child(7) > span').get_text()\n",
    "\n",
    "        model_vehicle.append([\n",
    "            month, int(company), int(model_id), int(volum.replace(',', '')), \n",
    "            float(share.replace('%', '')), int(mom.replace(',', '')), mos\n",
    "        ])\n",
    "\n",
    "    model_vehicle_df = pd.DataFrame(model_vehicle, columns=[\n",
    "        'model_date', 'company_id', 'model_id', 'sales_volume', 'model_share', \n",
    "        'model_month_over_month', 'model_salse_by_month'\n",
    "    ])\n",
    "    \n",
    "    return model_vehicle_df\n",
    "\n",
    "# making date and company list\n",
    "def making_list():\n",
    "    now = datetime.now()\n",
    "    previous_month = now - relativedelta(months=1)\n",
    "    crawl_months = []\n",
    "    for i in range(6):\n",
    "        month_date = previous_month - relativedelta(months=i)\n",
    "        crawl_months.append(month_date.strftime('%Y-%m'))\n",
    "    crawl_months.reverse()\n",
    "\n",
    "    crawl_companies = ['303', '304', '307']\n",
    "\n",
    "    return crawl_months, crawl_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKING DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define df and driver\n",
    "crawl_months, crawl_companies = making_list()\n",
    "model_df = pd.DataFrame()\n",
    "model_vehicle_df = pd.DataFrame()\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# crawling & making df\n",
    "for month in crawl_months:\n",
    "    for company in crawl_companies:\n",
    "        url = f'https://auto.danawa.com/auto/?Work=record&Tab=Model&Brand={company}&Month={month}-00&MonthTo='\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        tmp_model_df = make_model_df(soup)\n",
    "        tmp_model_vehicle_df = make_model_vehicle_df(company, month, soup)\n",
    "\n",
    "        model_df = pd.concat([model_df, tmp_model_df], ignore_index=True)\n",
    "        model_df = model_df.drop_dupWlicates(subset='model_id',keep='first')\n",
    "        \n",
    "        model_vehicle_df = pd.concat([model_vehicle_df, tmp_model_vehicle_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPEND MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making connection and insert data\n",
    "con = pymysql.connect (\n",
    "    host = 'localhost',\n",
    "    user = 'root',\n",
    "    password= 'root1234',\n",
    "    database= 'vehicle',\n",
    "    charset='utf8'\n",
    ")\n",
    "\n",
    "DATABASE_URI = 'mysql+pymysql://root:root1234@localhost:3306/vehicle'\n",
    "\n",
    "engine = create_engine(DATABASE_URI)\n",
    "\n",
    "model_df.to_sql('model', con=engine, if_exists='append', index=False)\n",
    "model_vehicle_df.to_sql('model_vehicle', con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
